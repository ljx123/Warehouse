#Describe/configure the agent
audit.sources = r1
audit.sinks = k1
audit.channels = c1
 
# Describe/configure the source
audit.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
audit.sources.r1.kafka.bootstrap.servers = hadoop5:9092,hadoop6:9092,hadoop7:9092
audit.sources.r1.kafka.topics = PhoneLogs
audit.sources.r1.kafka.consumer.group.id = audit
#audit.sources.r1.kafka.consumer.max.partition.fetch.bytes = 20485760
audit.sources.r1.interceptors = i1 
audit.sources.r1.interceptors.i1.type=timestamp
audit.sources.r1.interceptors.i1.preserveExisting=true
 
# Describe/configure the sink
audit.sinks.k1.type = hdfs
audit.sinks.k1.hdfs.path = hdfs://ns1/user/source/audit/%Y%m%d
audit.sinks.k1.hdfs.filePrefix = audit
audit.sinks.k1.hdfs.fileSuffix = .log
audit.sinks.k1.hdfs.useLocalTimeStamp = false
audit.sinks.k1.hdfs.fileType = DataStream
audit.sinks.k1.hdfs.writeFormat = Text
audit.sinks.k1.hdfs.batchSize = 10000
audit.sinks.k1.hdfs.rollSize = 0
audit.sinks.k1.hdfs.rollCount = 0
audit.sinks.k1.hdfs.rollInterval = 600
audit.sinks.k1.minBlockReplicas = 1
#当目前被打开的临时文件在该参数指定的时间（秒）内，没有任何数据写入，则将该临时文件关闭并重命名成目标文件
audit.sinks.k1.hdfs.idleTimeout=0
#执行HDFS操作的超时时间（单位：毫秒)
audit.sinks.k1.hdfs.callTimeout = 60000
#audit.sinks.k1.type = logger 

# Use a channel which buffers events in memory
audit.channels.c1.type = memory
audit.channels.c1.capacity = 10000000
audit.channels.c1.transactionCapacity = 100000
 
# Bind the source and sink to the channel
audit.sources.r1.channels= c1
audit.sinks.k1.channel = c1